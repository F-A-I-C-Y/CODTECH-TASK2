# -*- coding: utf-8 -*-
"""Task_2 (Predictive Modeling with Classification).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cqink6WnlLsq77xseYsHluWr9DptGFOE
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Load the Iris dataset
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = iris.target

# Define features and target variable
X = df.drop('species', axis=1)
y = df['species']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Load the Iris dataset
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = iris.target

# Define features and target variable
X = df.drop('species', axis=1)
y = df['species']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize and train the model
logreg = LogisticRegression()
logreg.fit(X_train, y_train)

# Make predictions
y_pred_logreg = logreg.predict(X_test)

# Evaluate the model
print("Logistic Regression:")
print("Accuracy:", accuracy_score(y_test, y_pred_logreg))
print("Precision:", precision_score(y_test, y_pred_logreg, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_logreg, average='weighted'))
print("F1 Score:", f1_score(y_test, y_pred_logreg, average='weighted'))
print("\nClassification Report:\n", classification_report(y_test, y_pred_logreg))

# Initialize and train the model
dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)

# Make predictions
y_pred_dtree = dtree.predict(X_test)

# Evaluate the model
print("Decision Tree Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred_dtree))
print("Precision:", precision_score(y_test, y_pred_dtree, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_dtree, average='weighted'))
print("F1 Score:", f1_score(y_test, y_pred_dtree, average='weighted'))
print("\nClassification Report:\n", classification_report(y_test, y_pred_dtree))

# Initialize and train the model
rforest = RandomForestClassifier()
rforest.fit(X_train, y_train)

# Make predictions
y_pred_rforest = rforest.predict(X_test)

# Evaluate the model
print("Random Forest Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred_rforest))
print("Precision:", precision_score(y_test, y_pred_rforest, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_rforest, average='weighted'))
print("F1 Score:", f1_score(y_test, y_pred_rforest, average='weighted'))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rforest))

# Initialize and train the model
svc = SVC()
svc.fit(X_train, y_train)

# Make predictions
y_pred_svc = svc.predict(X_test)

# Evaluate the model
print("Support Vector Classifier:")
print("Accuracy:", accuracy_score(y_test, y_pred_svc))
print("Precision:", precision_score(y_test, y_pred_svc, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_svc, average='weighted'))
print("F1 Score:", f1_score(y_test, y_pred_svc, average='weighted'))
print("\nClassification Report:\n", classification_report(y_test, y_pred_svc))

# Comparison summary
models = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Support Vector Classifier']
accuracies = [
    accuracy_score(y_test, y_pred_logreg),
    accuracy_score(y_test, y_pred_dtree),
    accuracy_score(y_test, y_pred_rforest),
    accuracy_score(y_test, y_pred_svc)
]

# Print comparison
for model, accuracy in zip(models, accuracies):
    print(f"{model} - Accuracy: {accuracy:.2f}")